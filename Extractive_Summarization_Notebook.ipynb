{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Extractive Summarization"
      ],
      "metadata": {
        "id": "FiBTl0F6ppBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Customer Feedback:\n",
        "\n",
        "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
        "They appreciated the quality of Reliance's petrochemical products, especially the high-grade polymers.\n",
        "A few minor issues regarding packaging were brought up, which need to be addressed.\n",
        "Customer's Future Requirements:\n",
        "\n",
        "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
        "They are interested in exploring Reliance's sustainable and green petrochemical offerings to meet their sustainability goals.\n",
        "Reliance Petrochemicals’ New Solutions:\n",
        "\n",
        "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n",
        "Provided a demo of the latest product enhancements and technical specifications.\n",
        "Supply Chain & Delivery Commitments:\n",
        "\n",
        "Discussion focused on how Reliance can ensure more consistent delivery during peak seasons.\n",
        "Proposed a real-time tracking system for better supply chain visibility, which the customer showed interest in.\n",
        "Collaboration Opportunities:\n",
        "\n",
        "The customer is open to a potential partnership for a joint research project in developing specialized polymers.\n",
        "Agreed to follow up with the technical teams on both sides for a deeper exploration.\n",
        "Action Items:\n",
        "For Reliance Petrochemicals:\n",
        "\n",
        "Investigate and resolve the packaging issues mentioned by the customer.\n",
        "Prepare a proposal for improving supply chain efficiency, especially during high-demand periods.\n",
        "Schedule a technical meeting to explore the research collaboration on specialized polymers.\n",
        "For the Customer:\n",
        "\n",
        "Provide Reliance with their quarterly demand forecast to help plan production and delivery schedules.\n",
        "Share sustainability requirements for products they are interested in, especially the biodegradable range.\"\"\""
      ],
      "metadata": {
        "id": "34Q3WbFnq7IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency-based Approach**"
      ],
      "metadata": {
        "id": "vOakxU-vqFbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # punkt tokenizer for sentence tokenization\n",
        "nltk.download('stopwords') # list of stop words, such as 'a', 'an', 'the', 'in', etc, which would be dropped\n",
        "from collections import Counter # Imports the Counter class from the collections module, used for counting the frequency of words in a text.\n",
        "from nltk.corpus import stopwords # Imports the stop words list from the NLTK corpus\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize # Imports the sentence tokenizer and word tokenizer from the NLTK tokenizer module.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PCHVt3NptV9",
        "outputId": "726a401d-26af-4a36-d819-bd4f7c912d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function would take 2 inputs, one being the text, and the other being the summary which would contain the number of lines\n",
        "def generate_summary(text, n):\n",
        "# Tokenize the text into individual sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "# Tokenize each sentence into individual words and remove stopwords\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "# tokenize each sentence from sentences into individual words using the word_tokenize function of nltk.tokenize module\n",
        "# removes any stop words and non-alphanumeric characters from the resulting list of words and converts them all to lowercase\n",
        "  words = [word.lower() for word in word_tokenize(text) if word.lower() not in stop_words and word.isalnum()]\n",
        "\n",
        "# Compute the frequency of each word\n",
        "  word_freq = Counter(words)\n",
        "\n",
        "# Compute the score for each sentence based on the frequency of its words\n",
        "# After this block of code is executed, sentence_scores will contain the scores of each sentence in the given text,\n",
        "# where each score is a sum of the frequency counts of its constituent words\n",
        "\n",
        "# empty dictionary to store the scores for each sentence\n",
        "  sentence_scores = {}\n",
        "\n",
        "  for sentence in sentences:\n",
        "    sentence_words = [word.lower() for word in word_tokenize(sentence) if word.lower() not in stop_words and word.isalnum()]\n",
        "    sentence_score = sum([word_freq[word] for word in sentence_words])\n",
        "    if len(sentence_words) < 30:\n",
        "      sentence_scores[sentence] = sentence_score\n",
        "\n",
        "# checks if the length of the sentence_words list is less than 30 (parameter can be adjusted based on the desired length of summary sentences)\n",
        "# If condition -> true, score of the current sentence is added to the sentence_scores dictionary with the sentence itself as the key\n",
        "# This is to filter out very short sentences that may not provide meaningful information for summary generation\n",
        "\n",
        "# Select the top n sentences with the highest scores\n",
        "  summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:n]\n",
        "  summary = ' '.join(summary_sentences)\n",
        "\n",
        "  return summary"
      ],
      "metadata": {
        "id": "KnxbLFi6sFJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = generate_summary(text, 6)\n",
        "summary_sentences = summary.split('. ')\n",
        "formatted_summary = '.\\n'.join(summary_sentences)\n",
        "\n",
        "print(formatted_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av7nzGjusSQV",
        "outputId": "37fff090-5035-4870-e5cd-dcdd977783fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback:\n",
            "\n",
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "Customer's Future Requirements:\n",
            "\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "Reliance Petrochemicals’ New Solutions:\n",
            "\n",
            "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n",
            "Supply Chain & Delivery Commitments:\n",
            "\n",
            "Discussion focused on how Reliance can ensure more consistent delivery during peak seasons.\n",
            "For the Customer:\n",
            "\n",
            "Provide Reliance with their quarterly demand forecast to help plan production and delivery schedules.\n",
            "Action Items:\n",
            "For Reliance Petrochemicals:\n",
            "\n",
            "Investigate and resolve the packaging issues mentioned by the customer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF Approach**"
      ],
      "metadata": {
        "id": "GjB_QTISxoIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# importing cosine_similarity function to compute the cosine similarity between two vectors.\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# importing nlargest to return the n largest elements from an iterable in descending order.\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "Kd8SuB_-sYv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_tfidf(text, n):\n",
        "# Tokenize the text into individual sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "# Create the TF-IDF matrix\n",
        "  vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(3,4) )\n",
        "  tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Compute the cosine similarity between each sentence and the document\n",
        "  sentence_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
        "\n",
        "# Select the top n sentences with the highest scores\n",
        "  summary_sentences = nlargest(n, range(len(sentence_scores)), key=sentence_scores.__getitem__)\n",
        "\n",
        "  summary_tfidf = ' '.join([sentences[i] for i in sorted(summary_sentences)])\n",
        "\n",
        "  return summary_tfidf"
      ],
      "metadata": {
        "id": "q5uUen37xwhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = generate_summary_tfidf(text, 6)\n",
        "summary_sentences = summary.split('. ')\n",
        "formatted_summary = '.\\n'.join(summary_sentences)\n",
        "\n",
        "print(formatted_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDofiO2ox3p0",
        "outputId": "07d986ed-4ebb-4044-9b8e-0e9cb84b9a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback:\n",
            "\n",
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "They appreciated the quality of Reliance's petrochemical products, especially the high-grade polymers.\n",
            "A few minor issues regarding packaging were brought up, which need to be addressed.\n",
            "Customer's Future Requirements:\n",
            "\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "They are interested in exploring Reliance's sustainable and green petrochemical offerings to meet their sustainability goals.\n",
            "Reliance Petrochemicals’ New Solutions:\n",
            "\n",
            "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count Vectorizer**"
      ],
      "metadata": {
        "id": "BNAuCHqiySe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Count Vectorizer Approach\n",
        "def generate_summary_cv(text, n):\n",
        "  # Tokenize the text into individual sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # Create the Count Vectorizer matrix\n",
        "  vectorizer = CountVectorizer(stop_words='english')\n",
        "  count_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "  # Compute the cosine similarity between each sentence and the document\n",
        "  sentence_scores = cosine_similarity(count_matrix[-1], count_matrix[:-1])[0]\n",
        "\n",
        "  # Select the top n sentences with the highest scores\n",
        "  summary_sentences = nlargest(n, range(len(sentence_scores)), key=sentence_scores.__getitem__)\n",
        "\n",
        "  summary_count = ' '.join([sentences[i] for i in sorted(summary_sentences)])\n",
        "\n",
        "  return summary_count\n"
      ],
      "metadata": {
        "id": "iuh4bKdkydGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = generate_summary_cv(text, 6)\n",
        "summary_sentences = summary.split('. ')\n",
        "formatted_summary = '.\\n'.join(summary_sentences)\n",
        "\n",
        "print(formatted_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbDM7uHRyff5",
        "outputId": "322d4560-a4a8-486f-c31f-343ba9dd4734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback:\n",
            "\n",
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "They appreciated the quality of Reliance's petrochemical products, especially the high-grade polymers.\n",
            "Customer's Future Requirements:\n",
            "\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "They are interested in exploring Reliance's sustainable and green petrochemical offerings to meet their sustainability goals.\n",
            "Reliance Petrochemicals’ New Solutions:\n",
            "\n",
            "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n",
            "Prepare a proposal for improving supply chain efficiency, especially during high-demand periods.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sumy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWtBYSt5FaA",
        "outputId": "b963d31f-d90c-43a9-bbc6-3f65f91ec37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
            "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21692 sha256=371d11717723fed334519746561dd17e6e6f92aaaeea26c361f085d1b0b62936\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d3637220ee8ce0cb9c9c3be5e98ce2e4d2d3e96f022b41add93db5e1c49ff267\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Luhn Summarizer**"
      ],
      "metadata": {
        "id": "zhmIwkEn_gyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words"
      ],
      "metadata": {
        "id": "2zWa3gkzysI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_luhn(paragraph, sentences_count=2):\n",
        "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
        "\n",
        "    summarizer = LuhnSummarizer(Stemmer(\"english\"))\n",
        "    summarizer.stop_words = get_stop_words(\"english\")\n",
        "\n",
        "    summary = summarizer(parser.document, sentences_count)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "rdggCVGY_n0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_count = 6\n",
        "summary = summarize_luhn(text, sentences_count)\n",
        "\n",
        "for sentence in summary:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jOHEnKE_8aN",
        "outputId": "06d3422e-b25c-4625-ec8e-a8a2ccc97fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "They are interested in exploring Reliance's sustainable and green petrochemical offerings to meet their sustainability goals.\n",
            "Supply Chain & Delivery Commitments:\n",
            "The customer is open to a potential partnership for a joint research project in developing specialized polymers.\n",
            "Investigate and resolve the packaging issues mentioned by the customer.\n",
            "Schedule a technical meeting to explore the research collaboration on specialized polymers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edmundson Summarizer**"
      ],
      "metadata": {
        "id": "VfadALQeD1si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.edmundson import EdmundsonSummarizer"
      ],
      "metadata": {
        "id": "itD2a1-YAC1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_Edmundson(paragraph, sentences_count=2, bonus_words=[''], stigma_words=[''], null_words=['']):\n",
        "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
        "\n",
        "    summarizer = EdmundsonSummarizer(Stemmer(\"english\"))\n",
        "    summarizer.stop_words = get_stop_words(\"english\")\n",
        "\n",
        "    summarizer.bonus_words = bonus_words\n",
        "\n",
        "    summarizer.stigma_words = stigma_words\n",
        "\n",
        "    summarizer.null_words = null_words\n",
        "\n",
        "    summary = summarizer(parser.document, sentences_count)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "rcASAlLrD6W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_count = 6\n",
        "summary = summarize_Edmundson(text, sentences_count)\n",
        "\n",
        "for sentence in summary:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi64xYVkEBJR",
        "outputId": "dd4647e9-366a-4317-e583-fdb8dafe2b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback:\n",
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "Customer's Future Requirements:\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "Provide Reliance with their quarterly demand forecast to help plan production and delivery schedules.\n",
            "Share sustainability requirements for products they are interested in, especially the biodegradable range.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSA Summarizer**"
      ],
      "metadata": {
        "id": "9TQKsFiNFkix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.lsa import LsaSummarizer"
      ],
      "metadata": {
        "id": "R_z6sQV8EEIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_LSA(paragraph, sentences_count=2):\n",
        "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
        "\n",
        "    summarizer = LsaSummarizer(Stemmer(\"english\"))\n",
        "    summarizer.stop_words = get_stop_words(\"english\")\n",
        "\n",
        "    summary = summarizer(parser.document, sentences_count)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "HkGwvbsiFoER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_count = 6\n",
        "summary = summarize_LSA(text, sentences_count)\n",
        "\n",
        "for sentence in summary:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "id": "voC9oPQBFyWM",
        "outputId": "3f72bef0-a67e-4aa8-fbc7-2063884a856d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n",
            "Proposed a real-time tracking system for better supply chain visibility, which the customer showed interest in.\n",
            "The customer is open to a potential partnership for a joint research project in developing specialized polymers.\n",
            "Prepare a proposal for improving supply chain efficiency, especially during high-demand periods.\n",
            "Provide Reliance with their quarterly demand forecast to help plan production and delivery schedules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TextRank**"
      ],
      "metadata": {
        "id": "jwuIahWM5PtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Packages\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer"
      ],
      "metadata": {
        "id": "JK8Lrwz7F0nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = PlaintextParser.from_string(text,Tokenizer(\"english\"))"
      ],
      "metadata": {
        "id": "munCwSuM5XmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize using sumy TextRank\n",
        "summarizer = TextRankSummarizer()\n",
        "summary =summarizer(parser.document,6)\n",
        "text_summary=\"\""
      ],
      "metadata": {
        "id": "L51V_l2d5drC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in summary:\n",
        "  print(sentence )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbYesysW5eej",
        "outputId": "9a18b438-c92a-467e-858e-360a31e85290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "They appreciated the quality of Reliance's petrochemical products, especially the high-grade polymers.\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "Introduced the customer to Reliance’s new line of biodegradable plastics and high-performance elastomers.\n",
            "Proposed a real-time tracking system for better supply chain visibility, which the customer showed interest in.\n",
            "The customer is open to a potential partnership for a joint research project in developing specialized polymers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KL Sum algorithm**"
      ],
      "metadata": {
        "id": "qV0r2BC_3Rmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.kl import KLSummarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words\n",
        "\n",
        "def summarize_kl_sum(paragraph, sentences_count):\n",
        "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
        "\n",
        "    summarizer = KLSummarizer(Stemmer(\"english\"))\n",
        "    summarizer.stop_words = get_stop_words(\"english\")\n",
        "\n",
        "    summary = summarizer(parser.document, sentences_count)\n",
        "    return summary\n",
        "\n",
        "summary = summarize_kl_sum(text, 10)\n",
        "\n",
        "for sentence in summary:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWGwzxhK3SUZ",
        "outputId": "167863d5-1355-4c12-99b2-cbce2f776328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Feedback:\n",
            "The customer expressed satisfaction with the overall supply of products but mentioned occasional delays in the supply chain during peak demand periods.\n",
            "A few minor issues regarding packaging were brought up, which need to be addressed.\n",
            "Customer's Future Requirements:\n",
            "The customer anticipates increased demand for polymer products in the next quarter due to a new project launch.\n",
            "Proposed a real-time tracking system for better supply chain visibility, which the customer showed interest in.\n",
            "Collaboration Opportunities:\n",
            "Investigate and resolve the packaging issues mentioned by the customer.\n",
            "Prepare a proposal for improving supply chain efficiency, especially during high-demand periods.\n",
            "For the Customer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7bgLW_e3Tbo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}